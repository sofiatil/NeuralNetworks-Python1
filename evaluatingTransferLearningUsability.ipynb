{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sofiatil/NeuralNetworks-Python1/blob/main/evaluatingTransferLearningUsability.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDFjnEersaWJ"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import load_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBrFGXtGFPxb",
        "outputId": "a6e057df-408f-45ea-d744-9f21fde78543"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSYuOgInENoS"
      },
      "outputs": [],
      "source": [
        "# Load the fashion-mnist dataset\n",
        "from keras.datasets import fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Visp5RmAri1l"
      },
      "outputs": [],
      "source": [
        "# image normalization\n",
        "train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Z-wFwpoEoJ9"
      },
      "outputs": [],
      "source": [
        "# label encoding to one-hot encoding\n",
        "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wd1MB8UTFUQy"
      },
      "outputs": [],
      "source": [
        "#define DNN and CNN model architectures\n",
        "\n",
        "def build_dnn_model():\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Flatten(input_shape=(28, 28, 1)))\n",
        "    model.add(layers.Dense(512, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(256, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "    return model\n",
        "\n",
        "DNN_from_scratch = build_dnn_model()\n",
        "DNN_from_scratch.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "DNN_from_scratch.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCKbKWLLfsuK"
      },
      "outputs": [],
      "source": [
        "def build_cnn_model():\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "    return model\n",
        "\n",
        "CNN_from_scratch = build_cnn_model()\n",
        "CNN_from_scratch.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "CNN_from_scratch.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdzNuASWeybO"
      },
      "outputs": [],
      "source": [
        "\n",
        "#define a method for calculating some classification metrics\n",
        "def calculate_metrics(y_true, y_pred):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average='macro')\n",
        "    recall = recall_score(y_true, y_pred, average='macro')\n",
        "    f1 = f1_score(y_true, y_pred, average='macro')\n",
        "    return accuracy, precision, recall, f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdMQ1YkFvxQw"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.models import save_model\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "dnn_models =[]\n",
        "\n",
        "num_folds = 6\n",
        "skf = StratifiedKFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "# define lists to hold the results\n",
        "results = []\n",
        "\n",
        "#save each one of the 6 models in a list, to get the best one after their evaluation\n",
        "dnn_models=[]\n",
        "\n",
        "# training the DNN model using stratified k fold validation\n",
        "for fold_idx, (train_index, val_index) in enumerate(skf.split(train_images, np.argmax(train_labels, axis=1))):\n",
        "    print(f\"Fold {fold_idx+1}/{num_folds}\")\n",
        "\n",
        "    # separate the train and validation sets\n",
        "    x_train, x_val = train_images[train_index], train_images[val_index]\n",
        "    y_train, y_val = train_labels[train_index], train_labels[val_index]\n",
        "\n",
        "    # load DNN model\n",
        "    DNN_from_scratch = build_dnn_model()\n",
        "    DNN_from_scratch.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # train the DNN model with train set and evaluate on validation set\n",
        "    dnn_history = DNN_from_scratch.fit(x_train, y_train, epochs=150, batch_size=32, validation_data=(x_val, y_val), verbose=1)\n",
        "\n",
        "\n",
        "    #after trainign predict the val labels\n",
        "    y_train_pred = DNN_from_scratch.predict(x_train)\n",
        "    y_test_pred = DNN_from_scratch.predict(test_images)\n",
        "\n",
        "    # evaluate the models on train and test sets\n",
        "    dnn_train_acc, dnn_train_precision, dnn_train_recall, dnn_train_f1 = calculate_metrics(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1))\n",
        "    dnn_test_acc, dnn_test_precision, dnn_test_recall, dnn_test_f1 = calculate_metrics(np.argmax(test_labels, axis=1), np.argmax(y_test_pred, axis=1))\n",
        "\n",
        "    #add model to the list\n",
        "    dnn_models.append(['DNN-'+str(fold_idx+1), DNN_from_scratch,dnn_test_f1])\n",
        "\n",
        "    # append the results\n",
        "    results.append(['DNN-FROM-SCRATCH', 'Train', fold_idx+1, dnn_train_acc, dnn_train_precision, dnn_train_recall, dnn_train_f1])\n",
        "    results.append(['DNN-FROM-SCRATCH', 'Test', fold_idx+1, dnn_test_acc, dnn_test_precision, dnn_test_recall, dnn_test_f1])\n",
        "\n",
        "#plot accuracy and loss for train-validation set (only for the last fold)\n",
        "plt.plot(dnn_history.history['accuracy'])\n",
        "plt.plot(dnn_history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(dnn_history.history['loss'])\n",
        "plt.plot(dnn_history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wocwpy6kxXxf",
        "outputId": "e0eb77e7-60cc-4723-d3f7-7430b7bfca14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1/6\n",
            "Epoch 1/150\n",
            "143/782 [====>.........................] - ETA: 36s - loss: 1.0481 - accuracy: 0.6175"
          ]
        }
      ],
      "source": [
        "cnn_models =[]\n",
        "\n",
        "# training the CNN model and evaluating\n",
        "for fold_idx, (train_index, val_index) in enumerate(skf.split(train_images, np.argmax(train_labels, axis=1))):\n",
        "    print(f\"Fold {fold_idx+1}/{num_folds}\")\n",
        "\n",
        "    # separate the train and validation sets\n",
        "    x_train, x_val = train_images[train_index], train_images[val_index]\n",
        "    y_train, y_val = train_labels[train_index], train_labels[val_index]\n",
        "\n",
        "    # load CNN model\n",
        "    CNN_from_scratch = build_cnn_model()\n",
        "    CNN_from_scratch.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # train the CNN model with validation set\n",
        "    cnn_history = CNN_from_scratch.fit(x_train, y_train, epochs=150, batch_size=64, validation_data=(x_val, y_val), verbose=1)\n",
        "\n",
        "    #after trainign predict the val labels\n",
        "    y_train_pred = CNN_from_scratch.predict(x_train)\n",
        "    y_test_pred = CNN_from_scratch.predict(test_images)\n",
        "\n",
        "    # evaluate the CNN model on train and test sets\n",
        "    cnn_train_acc, cnn_train_precision, cnn_train_recall, cnn_train_f1 = calculate_metrics(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1))\n",
        "    cnn_test_acc, cnn_test_precision, cnn_test_recall, cnn_test_f1 = calculate_metrics(np.argmax(test_labels, axis=1), np.argmax(y_test_pred, axis=1))\n",
        "\n",
        "    # append the current cnn model and its f1 score to the list\n",
        "    cnn_models.append(['CNN-'+str(fold_idx+1), CNN_from_scratch, cnn_test_f1])\n",
        "\n",
        "    # append the results\n",
        "    results.append(['CNN-FROM-SCRATCH', 'Train', fold_idx+1, cnn_train_acc, cnn_train_precision, cnn_train_recall, cnn_train_f1])\n",
        "    results.append(['CNN-FROM-SCRATCH', 'Test', fold_idx+1, cnn_test_acc, cnn_test_precision, cnn_test_recall, cnn_test_f1])\n",
        "\n",
        "#plot accuracy and loss for train-validation set (only for the last fold)\n",
        "plt.plot(cnn_history.history['accuracy'])\n",
        "plt.plot(cnn_history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(cnn_history.history['loss'])\n",
        "plt.plot(cnn_history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# Create DataFrame\n",
        "columns = ['Technique', 'Set', 'Fold', 'Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
        "results_df = pd.DataFrame(results, columns=columns)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot f1-score and precision for DNN_from_scratch CNN_from_scratch\n",
        "DNN_x_axis = ['DNN-1', 'DNN-2', 'DNN-3', 'DNN-4', 'DNN-5', 'DNN-6']\n",
        "DNN_prec_values = []\n",
        "DNN_f1_values=[]\n",
        "\n",
        "for ind in results_df.index:\n",
        "  if results_df['Technique'][ind]=='DNN-FROM-SCRATCH' and results_df['Set'][ind]=='Test':\n",
        "      DNN_prec_values.append(results_df['Precision'][ind])\n",
        "      DNN_f1_values.append(results_df['F1 Score'][ind])\n",
        "\n",
        "\n",
        "CNN_x_axis = ['CNN-1', 'CNN-2', 'CNN-3', 'CNN-4', 'CNN-5', 'CNN-6']\n",
        "CNN_prec_values = []\n",
        "CNN_f1_values=[]\n",
        "\n",
        "for ind in results_df.index:\n",
        "  if results_df['Technique'][ind]=='CNN-FROM-SCRATCH' and results_df['Set'][ind]=='Test':\n",
        "      # print(results_df['F1 Score'][ind])\n",
        "      CNN_prec_values.append(results_df['Precision'][ind])\n",
        "      CNN_f1_values.append(results_df['F1 Score'][ind])\n",
        "\n",
        "\n",
        "# Plot  F1-scores and precision for DNN models and CNN models\n",
        "# Compare the models of each architecture considering these two metrics\n",
        "\n",
        "\n",
        "plt.title(\"DNN_transfer precision in Test Set\")\n",
        "plt.bar(DNN_x_axis, DNN_prec_values)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fWpKYLgyu2r7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TuFY8euiECrC"
      },
      "outputs": [],
      "source": [
        "# Find the best DNN_from scratch and the best CNN_scratch\n",
        "\n",
        "dnn_f1_df = pd.DataFrame(dnn_models, columns = ['Model Name', 'Model Object', 'F1-Score'])\n",
        "best_ind = dnn_f1_df['F1-Score'].idxmax()\n",
        "best_dnn = dnn_f1_df.loc[best_ind, 'Model Object']\n",
        "\n",
        "\n",
        "cnn_f1_df = pd.DataFrame(cnn_models, columns = ['Model Name', 'Model Object', 'F1-Score'])\n",
        "best_ind = cnn_f1_df['F1-Score'].idxmax()\n",
        "best_dnn = cnn_f1_df.loc[best_ind, 'Model Object']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DNN **Transfer** - CNN **Transfer**\n",
        "\n"
      ],
      "metadata": {
        "id": "P3AgRVROsly4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbYpthqEXrSP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cb1f56b4-ea05-49ae-b9b4-f05aa69df6eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1/6\n",
            "Train only the last layer\n",
            "Epoch 1/40\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 2.1265 - accuracy: 0.3987 - val_loss: 1.1305 - val_accuracy: 0.6321\n",
            "Epoch 2/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.2584 - accuracy: 0.5384 - val_loss: 1.0583 - val_accuracy: 0.6505\n",
            "Epoch 3/40\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.2230 - accuracy: 0.5450 - val_loss: 1.0443 - val_accuracy: 0.6332\n",
            "Epoch 4/40\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.1960 - accuracy: 0.5569 - val_loss: 1.0241 - val_accuracy: 0.6429\n",
            "Epoch 5/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1847 - accuracy: 0.5574 - val_loss: 1.0181 - val_accuracy: 0.6497\n",
            "Epoch 6/40\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.1808 - accuracy: 0.5583 - val_loss: 1.0108 - val_accuracy: 0.6578\n",
            "Epoch 7/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1782 - accuracy: 0.5604 - val_loss: 0.9980 - val_accuracy: 0.6571\n",
            "Epoch 8/40\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.1728 - accuracy: 0.5621 - val_loss: 1.0060 - val_accuracy: 0.6489\n",
            "Epoch 9/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1718 - accuracy: 0.5595 - val_loss: 0.9968 - val_accuracy: 0.6665\n",
            "Epoch 10/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1710 - accuracy: 0.5599 - val_loss: 0.9982 - val_accuracy: 0.6633\n",
            "Epoch 11/40\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.1694 - accuracy: 0.5602 - val_loss: 0.9992 - val_accuracy: 0.6611\n",
            "Epoch 12/40\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.1717 - accuracy: 0.5628 - val_loss: 0.9959 - val_accuracy: 0.6593\n",
            "Epoch 13/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1779 - accuracy: 0.5581 - val_loss: 0.9938 - val_accuracy: 0.6641\n",
            "Epoch 14/40\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.1713 - accuracy: 0.5595 - val_loss: 0.9916 - val_accuracy: 0.6624\n",
            "Epoch 15/40\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.1702 - accuracy: 0.5633 - val_loss: 0.9927 - val_accuracy: 0.6551\n",
            "Epoch 16/40\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.1729 - accuracy: 0.5602 - val_loss: 0.9993 - val_accuracy: 0.6421\n",
            "Epoch 17/40\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.1692 - accuracy: 0.5608 - val_loss: 0.9951 - val_accuracy: 0.6484\n",
            "Epoch 18/40\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.1708 - accuracy: 0.5631 - val_loss: 0.9954 - val_accuracy: 0.6429\n",
            "Epoch 19/40\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 1.1657 - accuracy: 0.5624 - val_loss: 0.9936 - val_accuracy: 0.6542\n",
            "Epoch 20/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1703 - accuracy: 0.5612 - val_loss: 0.9940 - val_accuracy: 0.6533\n",
            "Epoch 21/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1709 - accuracy: 0.5645 - val_loss: 0.9895 - val_accuracy: 0.6652\n",
            "Epoch 22/40\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.1662 - accuracy: 0.5608 - val_loss: 0.9971 - val_accuracy: 0.6466\n",
            "Epoch 23/40\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.1670 - accuracy: 0.5616 - val_loss: 0.9945 - val_accuracy: 0.6567\n",
            "Epoch 24/40\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.1702 - accuracy: 0.5618 - val_loss: 0.9985 - val_accuracy: 0.6486\n",
            "Epoch 25/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1635 - accuracy: 0.5614 - val_loss: 0.9899 - val_accuracy: 0.6544\n",
            "Epoch 26/40\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.1739 - accuracy: 0.5599 - val_loss: 0.9921 - val_accuracy: 0.6633\n",
            "Epoch 27/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1710 - accuracy: 0.5622 - val_loss: 0.9885 - val_accuracy: 0.6574\n",
            "Epoch 28/40\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.1683 - accuracy: 0.5626 - val_loss: 0.9909 - val_accuracy: 0.6652\n",
            "Epoch 29/40\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.1720 - accuracy: 0.5607 - val_loss: 0.9998 - val_accuracy: 0.6476\n",
            "Epoch 30/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1726 - accuracy: 0.5581 - val_loss: 1.0093 - val_accuracy: 0.6353\n",
            "Epoch 31/40\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.1601 - accuracy: 0.5617 - val_loss: 0.9995 - val_accuracy: 0.6525\n",
            "Epoch 32/40\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.1693 - accuracy: 0.5605 - val_loss: 0.9891 - val_accuracy: 0.6525\n",
            "Epoch 33/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1671 - accuracy: 0.5601 - val_loss: 0.9889 - val_accuracy: 0.6538\n",
            "Epoch 34/40\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.1694 - accuracy: 0.5598 - val_loss: 0.9977 - val_accuracy: 0.6424\n",
            "Epoch 35/40\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.1731 - accuracy: 0.5613 - val_loss: 0.9988 - val_accuracy: 0.6419\n",
            "Epoch 36/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1629 - accuracy: 0.5623 - val_loss: 0.9957 - val_accuracy: 0.6589\n",
            "Epoch 37/40\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.1644 - accuracy: 0.5596 - val_loss: 0.9890 - val_accuracy: 0.6609\n",
            "Epoch 38/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1667 - accuracy: 0.5630 - val_loss: 0.9993 - val_accuracy: 0.6505\n",
            "Epoch 39/40\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.1707 - accuracy: 0.5599 - val_loss: 0.9934 - val_accuracy: 0.6483\n",
            "Epoch 40/40\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.1753 - accuracy: 0.5594 - val_loss: 0.9935 - val_accuracy: 0.6467\n",
            "Fine-Tunning Train End-To-End\n",
            "\n",
            "Epoch 1/20\n",
            "782/782 [==============================] - 11s 12ms/step - loss: 0.7679 - accuracy: 0.7153 - val_loss: 0.5166 - val_accuracy: 0.8149\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.5883 - accuracy: 0.7879 - val_loss: 0.4518 - val_accuracy: 0.8407\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.5281 - accuracy: 0.8093 - val_loss: 0.4438 - val_accuracy: 0.8382\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 0.4942 - accuracy: 0.8222 - val_loss: 0.4176 - val_accuracy: 0.8486\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 11s 13ms/step - loss: 0.4689 - accuracy: 0.8309 - val_loss: 0.4121 - val_accuracy: 0.8507\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.4565 - accuracy: 0.8362 - val_loss: 0.3953 - val_accuracy: 0.8639\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.4382 - accuracy: 0.8403 - val_loss: 0.3725 - val_accuracy: 0.8635\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.4235 - accuracy: 0.8466 - val_loss: 0.3802 - val_accuracy: 0.8595\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 11s 13ms/step - loss: 0.4142 - accuracy: 0.8488 - val_loss: 0.3699 - val_accuracy: 0.8644\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 11s 13ms/step - loss: 0.4059 - accuracy: 0.8531 - val_loss: 0.3602 - val_accuracy: 0.8728\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 10s 12ms/step - loss: 0.3924 - accuracy: 0.8566 - val_loss: 0.3564 - val_accuracy: 0.8747\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3903 - accuracy: 0.8591 - val_loss: 0.3492 - val_accuracy: 0.8738\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 11s 13ms/step - loss: 0.3831 - accuracy: 0.8600 - val_loss: 0.3469 - val_accuracy: 0.8773\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.3777 - accuracy: 0.8629 - val_loss: 0.3454 - val_accuracy: 0.8779\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.3703 - accuracy: 0.8635 - val_loss: 0.3640 - val_accuracy: 0.8667\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3702 - accuracy: 0.8632 - val_loss: 0.3537 - val_accuracy: 0.8738\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3654 - accuracy: 0.8669 - val_loss: 0.3493 - val_accuracy: 0.8746\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3628 - accuracy: 0.8650 - val_loss: 0.3623 - val_accuracy: 0.8682\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3518 - accuracy: 0.8703 - val_loss: 0.3513 - val_accuracy: 0.8704\n",
            "Epoch 20/20\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3542 - accuracy: 0.8681 - val_loss: 0.3430 - val_accuracy: 0.8810\n",
            "1563/1563 [==============================] - 5s 3ms/step\n",
            "313/313 [==============================] - 1s 3ms/step\n",
            "313/313 [==============================] - 1s 5ms/step\n",
            "Fold 2/6\n",
            "Train only the last layer\n",
            "Epoch 1/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 2.1428 - accuracy: 0.3955 - val_loss: 1.1105 - val_accuracy: 0.6315\n",
            "Epoch 2/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.2532 - accuracy: 0.5375 - val_loss: 1.0487 - val_accuracy: 0.6652\n",
            "Epoch 3/40\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.2111 - accuracy: 0.5497 - val_loss: 1.0196 - val_accuracy: 0.6638\n",
            "Epoch 4/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1949 - accuracy: 0.5548 - val_loss: 1.0102 - val_accuracy: 0.6671\n",
            "Epoch 5/40\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.1897 - accuracy: 0.5556 - val_loss: 0.9984 - val_accuracy: 0.6676\n",
            "Epoch 6/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1834 - accuracy: 0.5584 - val_loss: 1.0028 - val_accuracy: 0.6493\n",
            "Epoch 7/40\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.1770 - accuracy: 0.5599 - val_loss: 0.9867 - val_accuracy: 0.6649\n",
            "Epoch 8/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1774 - accuracy: 0.5601 - val_loss: 0.9937 - val_accuracy: 0.6577\n",
            "Epoch 9/40\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.1769 - accuracy: 0.5597 - val_loss: 0.9947 - val_accuracy: 0.6459\n",
            "Epoch 10/40\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.1774 - accuracy: 0.5611 - val_loss: 0.9884 - val_accuracy: 0.6611\n",
            "Epoch 11/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1704 - accuracy: 0.5607 - val_loss: 0.9850 - val_accuracy: 0.6557\n",
            "Epoch 12/40\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.1713 - accuracy: 0.5610 - val_loss: 0.9888 - val_accuracy: 0.6556\n",
            "Epoch 13/40\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.1762 - accuracy: 0.5588 - val_loss: 0.9839 - val_accuracy: 0.6594\n",
            "Epoch 14/40\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.1738 - accuracy: 0.5588 - val_loss: 0.9845 - val_accuracy: 0.6754\n",
            "Epoch 15/40\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.1666 - accuracy: 0.5615 - val_loss: 0.9866 - val_accuracy: 0.6648\n",
            "Epoch 16/40\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.1708 - accuracy: 0.5585 - val_loss: 0.9895 - val_accuracy: 0.6533\n",
            "Epoch 17/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1793 - accuracy: 0.5587 - val_loss: 0.9843 - val_accuracy: 0.6610\n",
            "Epoch 18/40\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.1732 - accuracy: 0.5643 - val_loss: 0.9889 - val_accuracy: 0.6571\n",
            "Epoch 19/40\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 1.1676 - accuracy: 0.5618 - val_loss: 0.9780 - val_accuracy: 0.6641\n",
            "Epoch 20/40\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.1685 - accuracy: 0.5603 - val_loss: 0.9897 - val_accuracy: 0.6502\n",
            "Epoch 21/40\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.1707 - accuracy: 0.5650 - val_loss: 0.9825 - val_accuracy: 0.6614\n",
            "Epoch 22/40\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.1667 - accuracy: 0.5609 - val_loss: 0.9784 - val_accuracy: 0.6646\n",
            "Epoch 23/40\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.1719 - accuracy: 0.5643 - val_loss: 0.9807 - val_accuracy: 0.6593\n",
            "Epoch 24/40\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.1719 - accuracy: 0.5586 - val_loss: 0.9854 - val_accuracy: 0.6561\n",
            "Epoch 25/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1716 - accuracy: 0.5595 - val_loss: 0.9820 - val_accuracy: 0.6550\n",
            "Epoch 26/40\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.1744 - accuracy: 0.5631 - val_loss: 0.9830 - val_accuracy: 0.6632\n",
            "Epoch 27/40\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.1720 - accuracy: 0.5614 - val_loss: 0.9850 - val_accuracy: 0.6576\n",
            "Epoch 28/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1710 - accuracy: 0.5573 - val_loss: 0.9793 - val_accuracy: 0.6659\n",
            "Epoch 29/40\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.1690 - accuracy: 0.5614 - val_loss: 0.9980 - val_accuracy: 0.6483\n",
            "Epoch 30/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1660 - accuracy: 0.5597 - val_loss: 0.9817 - val_accuracy: 0.6569\n",
            "Epoch 31/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1702 - accuracy: 0.5638 - val_loss: 0.9934 - val_accuracy: 0.6487\n",
            "Epoch 32/40\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.1706 - accuracy: 0.5608 - val_loss: 0.9867 - val_accuracy: 0.6500\n",
            "Epoch 33/40\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.1746 - accuracy: 0.5621 - val_loss: 0.9820 - val_accuracy: 0.6609\n",
            "Epoch 34/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1677 - accuracy: 0.5620 - val_loss: 0.9808 - val_accuracy: 0.6639\n",
            "Epoch 35/40\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.1665 - accuracy: 0.5590 - val_loss: 0.9913 - val_accuracy: 0.6533\n",
            "Epoch 36/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1665 - accuracy: 0.5610 - val_loss: 0.9864 - val_accuracy: 0.6518\n",
            "Epoch 37/40\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.1660 - accuracy: 0.5653 - val_loss: 0.9951 - val_accuracy: 0.6491\n",
            "Epoch 38/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1735 - accuracy: 0.5598 - val_loss: 0.9909 - val_accuracy: 0.6461\n",
            "Epoch 39/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1714 - accuracy: 0.5588 - val_loss: 0.9850 - val_accuracy: 0.6615\n",
            "Epoch 40/40\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.1703 - accuracy: 0.5610 - val_loss: 0.9791 - val_accuracy: 0.6594\n",
            "Fine-Tunning Train End-To-End\n",
            "\n",
            "Epoch 1/20\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.7724 - accuracy: 0.7139 - val_loss: 0.5208 - val_accuracy: 0.8158\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 11s 13ms/step - loss: 0.5940 - accuracy: 0.7855 - val_loss: 0.4484 - val_accuracy: 0.8417\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 0.5270 - accuracy: 0.8094 - val_loss: 0.4147 - val_accuracy: 0.8579\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.4895 - accuracy: 0.8228 - val_loss: 0.4035 - val_accuracy: 0.8592\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.4657 - accuracy: 0.8292 - val_loss: 0.3999 - val_accuracy: 0.8578\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 0.4495 - accuracy: 0.8356 - val_loss: 0.3753 - val_accuracy: 0.8676\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 11s 13ms/step - loss: 0.4301 - accuracy: 0.8434 - val_loss: 0.3725 - val_accuracy: 0.8699\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.4189 - accuracy: 0.8482 - val_loss: 0.3638 - val_accuracy: 0.8697\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.4074 - accuracy: 0.8498 - val_loss: 0.3656 - val_accuracy: 0.8678\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 0.4056 - accuracy: 0.8527 - val_loss: 0.3479 - val_accuracy: 0.8730\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.3918 - accuracy: 0.8559 - val_loss: 0.3491 - val_accuracy: 0.8715\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.3932 - accuracy: 0.8554 - val_loss: 0.3542 - val_accuracy: 0.8752\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3783 - accuracy: 0.8594 - val_loss: 0.3513 - val_accuracy: 0.8785\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3752 - accuracy: 0.8624 - val_loss: 0.3422 - val_accuracy: 0.8800\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 11s 13ms/step - loss: 0.3721 - accuracy: 0.8635 - val_loss: 0.3446 - val_accuracy: 0.8762\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.3643 - accuracy: 0.8654 - val_loss: 0.3393 - val_accuracy: 0.8788\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 0.3664 - accuracy: 0.8663 - val_loss: 0.3336 - val_accuracy: 0.8809\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3559 - accuracy: 0.8680 - val_loss: 0.3343 - val_accuracy: 0.8802\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 11s 13ms/step - loss: 0.3582 - accuracy: 0.8688 - val_loss: 0.3320 - val_accuracy: 0.8827\n",
            "Epoch 20/20\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 0.3475 - accuracy: 0.8712 - val_loss: 0.3344 - val_accuracy: 0.8825\n",
            "1563/1563 [==============================] - 9s 6ms/step\n",
            "313/313 [==============================] - 1s 3ms/step\n",
            "313/313 [==============================] - 1s 3ms/step\n",
            "Fold 3/6\n",
            "Train only the last layer\n",
            "Epoch 1/40\n",
            "782/782 [==============================] - 6s 6ms/step - loss: 2.1487 - accuracy: 0.3940 - val_loss: 1.1159 - val_accuracy: 0.6386\n",
            "Epoch 2/40\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.2517 - accuracy: 0.5391 - val_loss: 1.0525 - val_accuracy: 0.6521\n",
            "Epoch 3/40\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.2057 - accuracy: 0.5519 - val_loss: 1.0313 - val_accuracy: 0.6609\n",
            "Epoch 4/40\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 1.1951 - accuracy: 0.5549 - val_loss: 1.0150 - val_accuracy: 0.6584\n",
            "Epoch 5/40\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 1.1865 - accuracy: 0.5564 - val_loss: 1.0115 - val_accuracy: 0.6560\n",
            "Epoch 6/40\n",
            "782/782 [==============================] - 10s 12ms/step - loss: 1.1825 - accuracy: 0.5586 - val_loss: 1.0087 - val_accuracy: 0.6536\n",
            "Epoch 7/40\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 1.1791 - accuracy: 0.5581 - val_loss: 1.0012 - val_accuracy: 0.6593\n",
            "Epoch 8/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1783 - accuracy: 0.5584 - val_loss: 1.0021 - val_accuracy: 0.6484\n",
            "Epoch 9/40\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.1754 - accuracy: 0.5616 - val_loss: 1.0026 - val_accuracy: 0.6456\n",
            "Epoch 10/40\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 1.1684 - accuracy: 0.5649 - val_loss: 0.9959 - val_accuracy: 0.6530\n",
            "Epoch 11/40\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.1761 - accuracy: 0.5619 - val_loss: 0.9897 - val_accuracy: 0.6635\n",
            "Epoch 12/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1718 - accuracy: 0.5639 - val_loss: 0.9913 - val_accuracy: 0.6536\n",
            "Epoch 13/40\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.1755 - accuracy: 0.5581 - val_loss: 0.9927 - val_accuracy: 0.6569\n",
            "Epoch 14/40\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 1.1724 - accuracy: 0.5595 - val_loss: 0.9875 - val_accuracy: 0.6652\n",
            "Epoch 15/40\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 1.1752 - accuracy: 0.5605 - val_loss: 0.9853 - val_accuracy: 0.6641\n",
            "Epoch 16/40\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 1.1685 - accuracy: 0.5601 - val_loss: 0.9843 - val_accuracy: 0.6561\n",
            "Epoch 17/40\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 1.1650 - accuracy: 0.5628 - val_loss: 0.9942 - val_accuracy: 0.6480\n",
            "Epoch 18/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1683 - accuracy: 0.5634 - val_loss: 0.9878 - val_accuracy: 0.6491\n",
            "Epoch 19/40\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.1716 - accuracy: 0.5587 - val_loss: 0.9860 - val_accuracy: 0.6559\n",
            "Epoch 20/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1671 - accuracy: 0.5644 - val_loss: 0.9860 - val_accuracy: 0.6509\n",
            "Epoch 21/40\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.1630 - accuracy: 0.5634 - val_loss: 0.9789 - val_accuracy: 0.6644\n",
            "Epoch 22/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1708 - accuracy: 0.5618 - val_loss: 0.9873 - val_accuracy: 0.6484\n",
            "Epoch 23/40\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.1737 - accuracy: 0.5568 - val_loss: 0.9831 - val_accuracy: 0.6556\n",
            "Epoch 24/40\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.1726 - accuracy: 0.5585 - val_loss: 0.9881 - val_accuracy: 0.6529\n",
            "Epoch 25/40\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.1702 - accuracy: 0.5590 - val_loss: 0.9829 - val_accuracy: 0.6561\n",
            "Epoch 26/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1721 - accuracy: 0.5627 - val_loss: 0.9830 - val_accuracy: 0.6584\n",
            "Epoch 27/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1665 - accuracy: 0.5598 - val_loss: 0.9823 - val_accuracy: 0.6723\n",
            "Epoch 28/40\n",
            "782/782 [==============================] - 10s 12ms/step - loss: 1.1621 - accuracy: 0.5650 - val_loss: 0.9897 - val_accuracy: 0.6519\n",
            "Epoch 29/40\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 1.1657 - accuracy: 0.5604 - val_loss: 0.9777 - val_accuracy: 0.6649\n",
            "Epoch 30/40\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 1.1655 - accuracy: 0.5621 - val_loss: 0.9824 - val_accuracy: 0.6548\n",
            "Epoch 31/40\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 1.1677 - accuracy: 0.5615 - val_loss: 0.9833 - val_accuracy: 0.6592\n",
            "Epoch 32/40\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.1723 - accuracy: 0.5623 - val_loss: 0.9829 - val_accuracy: 0.6609\n",
            "Epoch 33/40\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.1700 - accuracy: 0.5621 - val_loss: 0.9865 - val_accuracy: 0.6527\n",
            "Epoch 34/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1697 - accuracy: 0.5597 - val_loss: 0.9898 - val_accuracy: 0.6482\n",
            "Epoch 35/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1713 - accuracy: 0.5601 - val_loss: 0.9864 - val_accuracy: 0.6612\n",
            "Epoch 36/40\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.1692 - accuracy: 0.5605 - val_loss: 0.9903 - val_accuracy: 0.6506\n",
            "Epoch 37/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1681 - accuracy: 0.5603 - val_loss: 0.9879 - val_accuracy: 0.6621\n",
            "Epoch 38/40\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.1681 - accuracy: 0.5581 - val_loss: 0.9912 - val_accuracy: 0.6429\n",
            "Epoch 39/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1694 - accuracy: 0.5612 - val_loss: 0.9768 - val_accuracy: 0.6620\n",
            "Epoch 40/40\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.1660 - accuracy: 0.5635 - val_loss: 0.9848 - val_accuracy: 0.6543\n",
            "Fine-Tunning Train End-To-End\n",
            "\n",
            "Epoch 1/20\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.7673 - accuracy: 0.7172 - val_loss: 0.5164 - val_accuracy: 0.8197\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.5929 - accuracy: 0.7849 - val_loss: 0.4522 - val_accuracy: 0.8433\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 0.5289 - accuracy: 0.8076 - val_loss: 0.4387 - val_accuracy: 0.8468\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.4931 - accuracy: 0.8206 - val_loss: 0.4025 - val_accuracy: 0.8586\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.4689 - accuracy: 0.8309 - val_loss: 0.4090 - val_accuracy: 0.8538\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.4490 - accuracy: 0.8376 - val_loss: 0.3903 - val_accuracy: 0.8607\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 0.4342 - accuracy: 0.8421 - val_loss: 0.3823 - val_accuracy: 0.8571\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.4245 - accuracy: 0.8446 - val_loss: 0.3776 - val_accuracy: 0.8690\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.4134 - accuracy: 0.8504 - val_loss: 0.3741 - val_accuracy: 0.8697\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.4059 - accuracy: 0.8520 - val_loss: 0.3656 - val_accuracy: 0.8705\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3994 - accuracy: 0.8554 - val_loss: 0.3571 - val_accuracy: 0.8721\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.3957 - accuracy: 0.8557 - val_loss: 0.3542 - val_accuracy: 0.8732\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.3830 - accuracy: 0.8582 - val_loss: 0.3440 - val_accuracy: 0.8740\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 0.3780 - accuracy: 0.8590 - val_loss: 0.3495 - val_accuracy: 0.8773\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.3751 - accuracy: 0.8627 - val_loss: 0.3531 - val_accuracy: 0.8767\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.3704 - accuracy: 0.8640 - val_loss: 0.3435 - val_accuracy: 0.8796\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.3665 - accuracy: 0.8655 - val_loss: 0.3409 - val_accuracy: 0.8799\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 10s 12ms/step - loss: 0.3643 - accuracy: 0.8667 - val_loss: 0.3461 - val_accuracy: 0.8807\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.3573 - accuracy: 0.8673 - val_loss: 0.3387 - val_accuracy: 0.8779\n",
            "Epoch 20/20\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.3538 - accuracy: 0.8700 - val_loss: 0.3467 - val_accuracy: 0.8789\n",
            "1563/1563 [==============================] - 6s 4ms/step\n",
            "313/313 [==============================] - 1s 3ms/step\n",
            "313/313 [==============================] - 1s 3ms/step\n",
            "Fold 4/6\n",
            "Train only the last layer\n",
            "Epoch 1/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 2.1159 - accuracy: 0.3987 - val_loss: 1.1109 - val_accuracy: 0.6544\n",
            "Epoch 2/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.2515 - accuracy: 0.5387 - val_loss: 1.0591 - val_accuracy: 0.6474\n",
            "Epoch 3/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.2105 - accuracy: 0.5499 - val_loss: 1.0304 - val_accuracy: 0.6566\n",
            "Epoch 4/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1861 - accuracy: 0.5559 - val_loss: 1.0218 - val_accuracy: 0.6548\n",
            "Epoch 5/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1814 - accuracy: 0.5582 - val_loss: 1.0170 - val_accuracy: 0.6486\n",
            "Epoch 6/40\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.1763 - accuracy: 0.5615 - val_loss: 1.0067 - val_accuracy: 0.6636\n",
            "Epoch 7/40\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.1770 - accuracy: 0.5567 - val_loss: 1.0051 - val_accuracy: 0.6536\n",
            "Epoch 8/40\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.1726 - accuracy: 0.5617 - val_loss: 1.0136 - val_accuracy: 0.6560\n",
            "Epoch 9/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1691 - accuracy: 0.5602 - val_loss: 0.9969 - val_accuracy: 0.6652\n",
            "Epoch 10/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1756 - accuracy: 0.5607 - val_loss: 1.0016 - val_accuracy: 0.6447\n",
            "Epoch 11/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1717 - accuracy: 0.5595 - val_loss: 0.9973 - val_accuracy: 0.6640\n",
            "Epoch 12/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1696 - accuracy: 0.5621 - val_loss: 0.9967 - val_accuracy: 0.6489\n",
            "Epoch 13/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1694 - accuracy: 0.5622 - val_loss: 0.9965 - val_accuracy: 0.6526\n",
            "Epoch 14/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1673 - accuracy: 0.5640 - val_loss: 1.0018 - val_accuracy: 0.6478\n",
            "Epoch 15/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1660 - accuracy: 0.5559 - val_loss: 1.0021 - val_accuracy: 0.6428\n",
            "Epoch 16/40\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.1663 - accuracy: 0.5618 - val_loss: 0.9996 - val_accuracy: 0.6403\n",
            "Epoch 17/40\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.1742 - accuracy: 0.5589 - val_loss: 0.9914 - val_accuracy: 0.6634\n",
            "Epoch 18/40\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.1682 - accuracy: 0.5585 - val_loss: 0.9950 - val_accuracy: 0.6572\n",
            "Epoch 19/40\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.1677 - accuracy: 0.5600 - val_loss: 0.9991 - val_accuracy: 0.6457\n",
            "Epoch 20/40\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.1646 - accuracy: 0.5602 - val_loss: 0.9984 - val_accuracy: 0.6457\n",
            "Epoch 21/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1678 - accuracy: 0.5601 - val_loss: 0.9912 - val_accuracy: 0.6596\n",
            "Epoch 22/40\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.1765 - accuracy: 0.5620 - val_loss: 0.9918 - val_accuracy: 0.6563\n",
            "Epoch 23/40\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.1664 - accuracy: 0.5622 - val_loss: 0.9906 - val_accuracy: 0.6556\n",
            "Epoch 24/40\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.1686 - accuracy: 0.5620 - val_loss: 0.9930 - val_accuracy: 0.6611\n",
            "Epoch 25/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1609 - accuracy: 0.5622 - val_loss: 0.9941 - val_accuracy: 0.6551\n",
            "Epoch 26/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1597 - accuracy: 0.5621 - val_loss: 0.9941 - val_accuracy: 0.6613\n",
            "Epoch 27/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1676 - accuracy: 0.5606 - val_loss: 0.9896 - val_accuracy: 0.6628\n",
            "Epoch 28/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1652 - accuracy: 0.5640 - val_loss: 0.9986 - val_accuracy: 0.6439\n",
            "Epoch 29/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1748 - accuracy: 0.5621 - val_loss: 0.9920 - val_accuracy: 0.6570\n",
            "Epoch 30/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1708 - accuracy: 0.5623 - val_loss: 0.9958 - val_accuracy: 0.6541\n",
            "Epoch 31/40\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.1682 - accuracy: 0.5630 - val_loss: 0.9981 - val_accuracy: 0.6427\n",
            "Epoch 32/40\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.1655 - accuracy: 0.5597 - val_loss: 0.9985 - val_accuracy: 0.6489\n",
            "Epoch 33/40\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.1637 - accuracy: 0.5622 - val_loss: 0.9947 - val_accuracy: 0.6483\n",
            "Epoch 34/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1666 - accuracy: 0.5627 - val_loss: 0.9915 - val_accuracy: 0.6500\n",
            "Epoch 35/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1654 - accuracy: 0.5612 - val_loss: 0.9977 - val_accuracy: 0.6625\n",
            "Epoch 36/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1664 - accuracy: 0.5598 - val_loss: 0.9898 - val_accuracy: 0.6628\n",
            "Epoch 37/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1675 - accuracy: 0.5592 - val_loss: 0.9958 - val_accuracy: 0.6584\n",
            "Epoch 38/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1692 - accuracy: 0.5595 - val_loss: 0.9931 - val_accuracy: 0.6586\n",
            "Epoch 39/40\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.1715 - accuracy: 0.5619 - val_loss: 0.9917 - val_accuracy: 0.6517\n",
            "Epoch 40/40\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.1660 - accuracy: 0.5612 - val_loss: 0.9935 - val_accuracy: 0.6491\n",
            "Fine-Tunning Train End-To-End\n",
            "\n",
            "Epoch 1/20\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.7609 - accuracy: 0.7192 - val_loss: 0.4985 - val_accuracy: 0.8206\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.5854 - accuracy: 0.7881 - val_loss: 0.4478 - val_accuracy: 0.8392\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.5218 - accuracy: 0.8119 - val_loss: 0.4198 - val_accuracy: 0.8500\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.4871 - accuracy: 0.8244 - val_loss: 0.4062 - val_accuracy: 0.8539\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.4591 - accuracy: 0.8321 - val_loss: 0.3888 - val_accuracy: 0.8620\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.4423 - accuracy: 0.8383 - val_loss: 0.3841 - val_accuracy: 0.8627\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 12s 16ms/step - loss: 0.4258 - accuracy: 0.8434 - val_loss: 0.3777 - val_accuracy: 0.8657\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.4168 - accuracy: 0.8471 - val_loss: 0.3780 - val_accuracy: 0.8633\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.4078 - accuracy: 0.8515 - val_loss: 0.3671 - val_accuracy: 0.8702\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.4007 - accuracy: 0.8543 - val_loss: 0.3667 - val_accuracy: 0.8717\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.3857 - accuracy: 0.8577 - val_loss: 0.3854 - val_accuracy: 0.8668\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 0.3853 - accuracy: 0.8588 - val_loss: 0.3607 - val_accuracy: 0.8744\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.3781 - accuracy: 0.8620 - val_loss: 0.3694 - val_accuracy: 0.8717\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.3739 - accuracy: 0.8613 - val_loss: 0.3537 - val_accuracy: 0.8791\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.3690 - accuracy: 0.8647 - val_loss: 0.3625 - val_accuracy: 0.8691\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 10s 12ms/step - loss: 0.3622 - accuracy: 0.8657 - val_loss: 0.3518 - val_accuracy: 0.8780\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.3590 - accuracy: 0.8659 - val_loss: 0.3453 - val_accuracy: 0.8782\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.3557 - accuracy: 0.8682 - val_loss: 0.3587 - val_accuracy: 0.8761\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 11s 13ms/step - loss: 0.3534 - accuracy: 0.8684 - val_loss: 0.3624 - val_accuracy: 0.8759\n",
            "Epoch 20/20\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3475 - accuracy: 0.8712 - val_loss: 0.3495 - val_accuracy: 0.8792\n",
            "1563/1563 [==============================] - 6s 4ms/step\n",
            "313/313 [==============================] - 1s 3ms/step\n",
            "313/313 [==============================] - 1s 3ms/step\n",
            "Fold 5/6\n",
            "Train only the last layer\n",
            "Epoch 1/40\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 2.1365 - accuracy: 0.3982 - val_loss: 1.1371 - val_accuracy: 0.6267\n",
            "Epoch 2/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.2505 - accuracy: 0.5368 - val_loss: 1.0819 - val_accuracy: 0.6335\n",
            "Epoch 3/40\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.2070 - accuracy: 0.5518 - val_loss: 1.0494 - val_accuracy: 0.6422\n",
            "Epoch 4/40\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.1942 - accuracy: 0.5550 - val_loss: 1.0363 - val_accuracy: 0.6491\n",
            "Epoch 5/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1889 - accuracy: 0.5562 - val_loss: 1.0393 - val_accuracy: 0.6461\n",
            "Epoch 6/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1773 - accuracy: 0.5600 - val_loss: 1.0244 - val_accuracy: 0.6396\n",
            "Epoch 7/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1780 - accuracy: 0.5612 - val_loss: 1.0255 - val_accuracy: 0.6376\n",
            "Epoch 8/40\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.1702 - accuracy: 0.5635 - val_loss: 1.0230 - val_accuracy: 0.6572\n",
            "Epoch 9/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1759 - accuracy: 0.5597 - val_loss: 1.0196 - val_accuracy: 0.6376\n",
            "Epoch 10/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1700 - accuracy: 0.5611 - val_loss: 1.0184 - val_accuracy: 0.6395\n",
            "Epoch 11/40\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.1626 - accuracy: 0.5618 - val_loss: 1.0143 - val_accuracy: 0.6566\n",
            "Epoch 12/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1608 - accuracy: 0.5651 - val_loss: 1.0146 - val_accuracy: 0.6396\n",
            "Epoch 13/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1618 - accuracy: 0.5644 - val_loss: 1.0073 - val_accuracy: 0.6539\n",
            "Epoch 14/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1676 - accuracy: 0.5593 - val_loss: 1.0158 - val_accuracy: 0.6443\n",
            "Epoch 15/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1673 - accuracy: 0.5622 - val_loss: 1.0053 - val_accuracy: 0.6518\n",
            "Epoch 16/40\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 1.1629 - accuracy: 0.5621 - val_loss: 1.0094 - val_accuracy: 0.6413\n",
            "Epoch 17/40\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.1669 - accuracy: 0.5653 - val_loss: 1.0167 - val_accuracy: 0.6396\n",
            "Epoch 18/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1652 - accuracy: 0.5646 - val_loss: 1.0167 - val_accuracy: 0.6301\n",
            "Epoch 19/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1661 - accuracy: 0.5589 - val_loss: 1.0114 - val_accuracy: 0.6428\n",
            "Epoch 20/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1665 - accuracy: 0.5598 - val_loss: 1.0036 - val_accuracy: 0.6479\n",
            "Epoch 21/40\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.1651 - accuracy: 0.5626 - val_loss: 1.0094 - val_accuracy: 0.6463\n",
            "Epoch 22/40\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.1691 - accuracy: 0.5629 - val_loss: 1.0151 - val_accuracy: 0.6449\n",
            "Epoch 23/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1625 - accuracy: 0.5652 - val_loss: 1.0068 - val_accuracy: 0.6470\n",
            "Epoch 24/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1692 - accuracy: 0.5593 - val_loss: 1.0224 - val_accuracy: 0.6255\n",
            "Epoch 25/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1651 - accuracy: 0.5623 - val_loss: 1.0064 - val_accuracy: 0.6480\n",
            "Epoch 26/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1647 - accuracy: 0.5619 - val_loss: 1.0132 - val_accuracy: 0.6312\n",
            "Epoch 27/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1608 - accuracy: 0.5610 - val_loss: 1.0011 - val_accuracy: 0.6536\n",
            "Epoch 28/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1675 - accuracy: 0.5636 - val_loss: 1.0243 - val_accuracy: 0.6471\n",
            "Epoch 29/40\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.1587 - accuracy: 0.5607 - val_loss: 1.0036 - val_accuracy: 0.6394\n",
            "Epoch 30/40\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.1667 - accuracy: 0.5623 - val_loss: 1.0134 - val_accuracy: 0.6285\n",
            "Epoch 31/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1594 - accuracy: 0.5662 - val_loss: 1.0109 - val_accuracy: 0.6401\n",
            "Epoch 32/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1640 - accuracy: 0.5625 - val_loss: 1.0129 - val_accuracy: 0.6394\n",
            "Epoch 33/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1671 - accuracy: 0.5616 - val_loss: 1.0104 - val_accuracy: 0.6525\n",
            "Epoch 34/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1635 - accuracy: 0.5624 - val_loss: 1.0094 - val_accuracy: 0.6537\n",
            "Epoch 35/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1608 - accuracy: 0.5619 - val_loss: 1.0063 - val_accuracy: 0.6391\n",
            "Epoch 36/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1620 - accuracy: 0.5612 - val_loss: 1.0112 - val_accuracy: 0.6315\n",
            "Epoch 37/40\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.1653 - accuracy: 0.5608 - val_loss: 1.0092 - val_accuracy: 0.6436\n",
            "Epoch 38/40\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.1663 - accuracy: 0.5609 - val_loss: 1.0083 - val_accuracy: 0.6378\n",
            "Epoch 39/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1675 - accuracy: 0.5605 - val_loss: 1.0116 - val_accuracy: 0.6448\n",
            "Epoch 40/40\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.1639 - accuracy: 0.5624 - val_loss: 1.0091 - val_accuracy: 0.6464\n",
            "Fine-Tunning Train End-To-End\n",
            "\n",
            "Epoch 1/20\n",
            "782/782 [==============================] - 11s 13ms/step - loss: 0.7617 - accuracy: 0.7159 - val_loss: 0.5152 - val_accuracy: 0.8182\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.5880 - accuracy: 0.7890 - val_loss: 0.4548 - val_accuracy: 0.8386\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.5264 - accuracy: 0.8116 - val_loss: 0.4180 - val_accuracy: 0.8507\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 11s 15ms/step - loss: 0.4956 - accuracy: 0.8204 - val_loss: 0.4026 - val_accuracy: 0.8578\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 10s 12ms/step - loss: 0.4717 - accuracy: 0.8294 - val_loss: 0.3956 - val_accuracy: 0.8609\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.4552 - accuracy: 0.8356 - val_loss: 0.3862 - val_accuracy: 0.8674\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.4400 - accuracy: 0.8394 - val_loss: 0.3807 - val_accuracy: 0.8641\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 11s 15ms/step - loss: 0.4257 - accuracy: 0.8449 - val_loss: 0.3720 - val_accuracy: 0.8689\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.4146 - accuracy: 0.8512 - val_loss: 0.3695 - val_accuracy: 0.8696\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.4069 - accuracy: 0.8517 - val_loss: 0.3612 - val_accuracy: 0.8720\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.4037 - accuracy: 0.8536 - val_loss: 0.3598 - val_accuracy: 0.8736\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.3945 - accuracy: 0.8560 - val_loss: 0.3585 - val_accuracy: 0.8730\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3880 - accuracy: 0.8581 - val_loss: 0.3485 - val_accuracy: 0.8753\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 11s 13ms/step - loss: 0.3817 - accuracy: 0.8613 - val_loss: 0.3459 - val_accuracy: 0.8754\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.3755 - accuracy: 0.8642 - val_loss: 0.3551 - val_accuracy: 0.8732\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 11s 15ms/step - loss: 0.3729 - accuracy: 0.8639 - val_loss: 0.3380 - val_accuracy: 0.8781\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.3648 - accuracy: 0.8664 - val_loss: 0.3431 - val_accuracy: 0.8720\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.3668 - accuracy: 0.8660 - val_loss: 0.3469 - val_accuracy: 0.8769\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 11s 15ms/step - loss: 0.3623 - accuracy: 0.8676 - val_loss: 0.3455 - val_accuracy: 0.8728\n",
            "Epoch 20/20\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.3573 - accuracy: 0.8706 - val_loss: 0.3294 - val_accuracy: 0.8816\n",
            "1563/1563 [==============================] - 5s 3ms/step\n",
            "313/313 [==============================] - 1s 3ms/step\n",
            "313/313 [==============================] - 1s 3ms/step\n",
            "Fold 6/6\n",
            "Train only the last layer\n",
            "Epoch 1/40\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 2.1139 - accuracy: 0.3945 - val_loss: 1.1241 - val_accuracy: 0.6341\n",
            "Epoch 2/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.2471 - accuracy: 0.5393 - val_loss: 1.0555 - val_accuracy: 0.6425\n",
            "Epoch 3/40\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 1.2105 - accuracy: 0.5467 - val_loss: 1.0262 - val_accuracy: 0.6557\n",
            "Epoch 4/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1933 - accuracy: 0.5559 - val_loss: 1.0189 - val_accuracy: 0.6501\n",
            "Epoch 5/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1823 - accuracy: 0.5580 - val_loss: 1.0145 - val_accuracy: 0.6410\n",
            "Epoch 6/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1783 - accuracy: 0.5595 - val_loss: 1.0025 - val_accuracy: 0.6463\n",
            "Epoch 7/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1831 - accuracy: 0.5572 - val_loss: 1.0028 - val_accuracy: 0.6561\n",
            "Epoch 8/40\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.1712 - accuracy: 0.5627 - val_loss: 0.9953 - val_accuracy: 0.6545\n",
            "Epoch 9/40\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.1726 - accuracy: 0.5590 - val_loss: 0.9962 - val_accuracy: 0.6545\n",
            "Epoch 10/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1780 - accuracy: 0.5593 - val_loss: 0.9893 - val_accuracy: 0.6577\n",
            "Epoch 11/40\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.1721 - accuracy: 0.5585 - val_loss: 0.9883 - val_accuracy: 0.6569\n",
            "Epoch 12/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1729 - accuracy: 0.5605 - val_loss: 0.9958 - val_accuracy: 0.6478\n",
            "Epoch 13/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1663 - accuracy: 0.5613 - val_loss: 0.9947 - val_accuracy: 0.6452\n",
            "Epoch 14/40\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 1.1621 - accuracy: 0.5636 - val_loss: 0.9859 - val_accuracy: 0.6532\n",
            "Epoch 15/40\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.1709 - accuracy: 0.5606 - val_loss: 0.9833 - val_accuracy: 0.6563\n",
            "Epoch 16/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1765 - accuracy: 0.5605 - val_loss: 0.9907 - val_accuracy: 0.6413\n",
            "Epoch 17/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1679 - accuracy: 0.5607 - val_loss: 0.9954 - val_accuracy: 0.6601\n",
            "Epoch 18/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1702 - accuracy: 0.5612 - val_loss: 0.9936 - val_accuracy: 0.6524\n",
            "Epoch 19/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1697 - accuracy: 0.5649 - val_loss: 0.9829 - val_accuracy: 0.6556\n",
            "Epoch 20/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1682 - accuracy: 0.5617 - val_loss: 0.9838 - val_accuracy: 0.6572\n",
            "Epoch 21/40\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.1716 - accuracy: 0.5610 - val_loss: 0.9938 - val_accuracy: 0.6483\n",
            "Epoch 22/40\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.1642 - accuracy: 0.5621 - val_loss: 0.9885 - val_accuracy: 0.6418\n",
            "Epoch 23/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1615 - accuracy: 0.5666 - val_loss: 0.9849 - val_accuracy: 0.6476\n",
            "Epoch 24/40\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.1696 - accuracy: 0.5636 - val_loss: 0.9875 - val_accuracy: 0.6491\n",
            "Epoch 25/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1719 - accuracy: 0.5600 - val_loss: 0.9863 - val_accuracy: 0.6523\n",
            "Epoch 26/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1701 - accuracy: 0.5597 - val_loss: 0.9923 - val_accuracy: 0.6384\n",
            "Epoch 27/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1647 - accuracy: 0.5597 - val_loss: 0.9845 - val_accuracy: 0.6503\n",
            "Epoch 28/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1642 - accuracy: 0.5634 - val_loss: 0.9802 - val_accuracy: 0.6527\n",
            "Epoch 29/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1726 - accuracy: 0.5614 - val_loss: 0.9904 - val_accuracy: 0.6470\n",
            "Epoch 30/40\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.1653 - accuracy: 0.5620 - val_loss: 0.9889 - val_accuracy: 0.6528\n",
            "Epoch 31/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1690 - accuracy: 0.5600 - val_loss: 0.9872 - val_accuracy: 0.6581\n",
            "Epoch 32/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1704 - accuracy: 0.5641 - val_loss: 0.9880 - val_accuracy: 0.6510\n",
            "Epoch 33/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1711 - accuracy: 0.5599 - val_loss: 0.9856 - val_accuracy: 0.6546\n",
            "Epoch 34/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1699 - accuracy: 0.5593 - val_loss: 0.9896 - val_accuracy: 0.6448\n",
            "Epoch 35/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1720 - accuracy: 0.5603 - val_loss: 0.9869 - val_accuracy: 0.6517\n",
            "Epoch 36/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1660 - accuracy: 0.5608 - val_loss: 0.9832 - val_accuracy: 0.6535\n",
            "Epoch 37/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1688 - accuracy: 0.5597 - val_loss: 0.9893 - val_accuracy: 0.6572\n",
            "Epoch 38/40\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.1716 - accuracy: 0.5595 - val_loss: 0.9896 - val_accuracy: 0.6481\n",
            "Epoch 39/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1619 - accuracy: 0.5616 - val_loss: 0.9811 - val_accuracy: 0.6585\n",
            "Epoch 40/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1705 - accuracy: 0.5583 - val_loss: 0.9804 - val_accuracy: 0.6548\n",
            "Fine-Tunning Train End-To-End\n",
            "\n",
            "Epoch 1/20\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.7620 - accuracy: 0.7211 - val_loss: 0.5078 - val_accuracy: 0.8259\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 11s 15ms/step - loss: 0.5856 - accuracy: 0.7889 - val_loss: 0.4467 - val_accuracy: 0.8424\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.5238 - accuracy: 0.8114 - val_loss: 0.4228 - val_accuracy: 0.8549\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 11s 13ms/step - loss: 0.4951 - accuracy: 0.8219 - val_loss: 0.4119 - val_accuracy: 0.8526\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 11s 15ms/step - loss: 0.4625 - accuracy: 0.8314 - val_loss: 0.3875 - val_accuracy: 0.8658\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.4423 - accuracy: 0.8362 - val_loss: 0.3720 - val_accuracy: 0.8707\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.4304 - accuracy: 0.8421 - val_loss: 0.3646 - val_accuracy: 0.8700\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.4200 - accuracy: 0.8470 - val_loss: 0.3735 - val_accuracy: 0.8678\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.4058 - accuracy: 0.8512 - val_loss: 0.3603 - val_accuracy: 0.8755\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 11s 15ms/step - loss: 0.4027 - accuracy: 0.8514 - val_loss: 0.3594 - val_accuracy: 0.8762\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.3914 - accuracy: 0.8549 - val_loss: 0.3546 - val_accuracy: 0.8779\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3898 - accuracy: 0.8570 - val_loss: 0.3515 - val_accuracy: 0.8783\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 11s 15ms/step - loss: 0.3806 - accuracy: 0.8601 - val_loss: 0.3511 - val_accuracy: 0.8789\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 11s 15ms/step - loss: 0.3772 - accuracy: 0.8615 - val_loss: 0.3451 - val_accuracy: 0.8807\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.3711 - accuracy: 0.8634 - val_loss: 0.3449 - val_accuracy: 0.8857\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3667 - accuracy: 0.8649 - val_loss: 0.3415 - val_accuracy: 0.8844\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.3620 - accuracy: 0.8679 - val_loss: 0.3434 - val_accuracy: 0.8777\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.3552 - accuracy: 0.8685 - val_loss: 0.3340 - val_accuracy: 0.8868\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3550 - accuracy: 0.8693 - val_loss: 0.3351 - val_accuracy: 0.8885\n",
            "Epoch 20/20\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.3515 - accuracy: 0.8701 - val_loss: 0.3365 - val_accuracy: 0.8894\n",
            "1563/1563 [==============================] - 7s 4ms/step\n",
            "313/313 [==============================] - 1s 3ms/step\n",
            "313/313 [==============================] - 1s 3ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "\n",
        "# define a list to store the DNN_transfer models and their F1-scores in the test set\n",
        "dnn_trans_models=[]\n",
        "results=[]\n",
        "\n",
        "num_folds = 6\n",
        "skf = StratifiedKFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "\n",
        "for fold_idx, (train_index, val_index) in enumerate(skf.split(train_images, np.argmax(train_labels, axis=1))):\n",
        "    print(f\"Fold {fold_idx+1}/{num_folds}\")\n",
        "\n",
        "    # Separate train and validation sets\n",
        "    x_train, x_val = train_images[train_index], train_images[val_index]\n",
        "    y_train, y_val = train_labels[train_index], train_labels[val_index]\n",
        "\n",
        "\n",
        "    # Compile the model\n",
        "    DNN_transfer = load_model(\"/content/drive/MyDrive/Neural Networks - assignment 1/bestDNN.h5\")\n",
        "\n",
        "    # Freeze layers except the last one\n",
        "    for layer in DNN_transfer.layers[:-1]:\n",
        "       layer.trainable = False\n",
        "\n",
        "    # train only the last layer\n",
        "    print('Train only the last layer')\n",
        "    DNN_transfer.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    DNN_transfer.fit(x_train, y_train, epochs=40, batch_size=64, validation_data=(x_val, y_val), verbose=1)\n",
        "\n",
        "    # unfreeze\n",
        "    for layer in DNN_transfer.layers:\n",
        "        layer.trainable = True\n",
        "\n",
        "    print(\"Fine-Tunning Train End-To-End\\n\")\n",
        "\n",
        "    # End-to-end training for 20 epochs\n",
        "    DNN_transfer.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    dnn_history_transfer = DNN_transfer.fit(x_train, y_train, epochs=20, batch_size=64, validation_data=(x_val, y_val), verbose=1)\n",
        "    y_train_pred = DNN_transfer.predict(x_train)\n",
        "    y_test_pred = DNN_transfer.predict(test_images)\n",
        "\n",
        "    # Evaluate the model\n",
        "    dnn_train_acc2, dnn_train_precision2, dnn_train_recall2, dnn_train_f12 = calculate_metrics(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1))\n",
        "    dnn_test_acc2, dnn_test_precision2, dnn_test_recall2, dnn_test_f12 = calculate_metrics(np.argmax(test_labels, axis=1), np.argmax(DNN_transfer.predict(test_images), axis=1))\n",
        "\n",
        "    # append the current cnn model and its f1 score to the list\n",
        "    dnn_trans_models.append(['DNN-'+str(fold_idx+1), DNN_transfer, dnn_test_f12])\n",
        "\n",
        "    # Append the results\n",
        "    results.append(['DNN_transfer', 'Train', fold_idx+1, dnn_train_acc2, dnn_train_precision2, dnn_train_recall2, dnn_train_f12])\n",
        "    results.append(['DNN_transfer', 'Test', fold_idx+1, dnn_test_acc2, dnn_test_precision2, dnn_test_recall2, dnn_test_f12])\n",
        "\n",
        "\n",
        "\n",
        "#plot accuracy and loss for train-validation set (only for the last fold) (DNN)\n",
        "plt.plot(dnn_history_transfer.history['accuracy'])\n",
        "plt.plot(dnn_history_transfer.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(dnn_history_transfer.history['loss'])\n",
        "plt.plot(dnn_history_transfer.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4ntzaKa36ll"
      },
      "outputs": [],
      "source": [
        "\n",
        "# create a list to save CNN_transfer models with their f1-scores on test set\n",
        "cnn_trans_models = []\n",
        "\n",
        "\n",
        "for fold_idx, (train_index, val_index) in enumerate(skf.split(train_images, np.argmax(train_labels, axis=1))):\n",
        "    print(f\"Fold {fold_idx+1}/{num_folds}\")\n",
        "\n",
        "    # Separate train and validation sets\n",
        "    x_train, x_val = train_images[train_index], train_images[val_index]\n",
        "    y_train, y_val = train_labels[train_index], train_labels[val_index]\n",
        "\n",
        "    # load the pre-trained CNN\n",
        "    CNN_transfer = load_model(\"/content/drive/MyDrive/Neural Networks - assignment 1/bestCNN.h5\")\n",
        "\n",
        "    # Freeze layers except the last one\n",
        "    for layer in CNN_transfer.layers[:-1]:\n",
        "      layer.trainable = False\n",
        "\n",
        "    CNN_transfer.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # train only the last layer\n",
        "    cnn_history_transfer = CNN_transfer.fit(x_train, y_train, epochs=40, batch_size=64, validation_data=(x_val, y_val), verbose=1)\n",
        "\n",
        "    # unfreeze the convolutional layers and train end-to-end\n",
        "    for layer in CNN_transfer.layers:\n",
        "      layer.trainable = True\n",
        "\n",
        "\n",
        "    # Continue training for 20 epochs\n",
        "    CNN_transfer.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    cnn_history_transfer = CNN_transfer.fit(x_train, y_train, epochs=20, batch_size=64, validation_data=(x_val, y_val), verbose=1)\n",
        "\n",
        "    y_train_pred = CNN_transfer.predict(x_train)\n",
        "    y_test_pred = CNN_transfer.predict(test_images)\n",
        "\n",
        "    # Evaluate the model\n",
        "    cnn_train_acc2, cnn_train_precision2, cnn_train_recall2, cnn_train_f12 = calculate_metrics(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1))\n",
        "    cnn_test_acc2, cnn_test_precision2, cnn_test_recall2, cnn_test_f12 = calculate_metrics(np.argmax(test_labels, axis=1), np.argmax(CNN_transfer.predict(test_images), axis=1))\n",
        "\n",
        "    cnn_trans_models.append(['CNN-'+str(fold_idx+1), CNN_transfer, cnn_test_f12])\n",
        "\n",
        "    # Append the results\n",
        "    results.append(['CNN_transfer', 'Train', fold_idx+1, cnn_train_acc2, cnn_train_precision2, cnn_train_recall2, cnn_train_f12])\n",
        "    results.append(['CNN_transfer', 'Test', fold_idx+1, cnn_test_acc2, cnn_test_precision2, cnn_test_recall2, cnn_test_f12])\n",
        "\n",
        "\n",
        "#plot accuracy and loss for train-validation set (only for the last fold) (CNN)\n",
        "plt.plot(cnn_history_transfer.history['accuracy'])\n",
        "plt.plot(cnn_history_transfer.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(cnn_history_transfer.history['loss'])\n",
        "plt.plot(cnn_history_transfer.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns = ['Technique', 'Set', 'Fold', 'Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
        "results_df = pd.DataFrame(results, columns=columns)\n",
        "\n",
        "# Save DataFrame as CSV\n",
        "# results_df.to_csv('erotima2.csv', index=False)\n",
        "results_df.to_csv('transfer.csv', index=False)"
      ],
      "metadata": {
        "id": "woynsaWkHVWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot  F1-scores and precision for DNN models and CNN models\n",
        "# Compare the models of each architecture considering these two metrics\n",
        "\n",
        "DNN_trans_x_axis = ['DNN-1', 'DNN-2', 'DNN-3', 'DNN-4', 'DNN-5', 'DNN-6']\n",
        "DNN_trans_prec_values = []\n",
        "DNN_trans_f1_values=[]\n",
        "\n",
        "for ind in results_df.index:\n",
        "  if results_df['Technique'][ind]=='DNN_transfer' and results_df['Set'][ind]=='Test':\n",
        "      DNN_trans_prec_values.append(results_df['Precision'][ind])\n",
        "      DNN_trans_f1_values.append(results_df['F1 Score'][ind])\n",
        "\n",
        "\n",
        "CNN_trans_x_axis = ['CNN-1', 'CNN-2', 'CNN-3', 'CNN-4', 'CNN-5', 'CNN-6']\n",
        "CNN_trans_prec_values = []\n",
        "CNN_trans_f1_values=[]\n",
        "\n",
        "for ind in results_df.index:\n",
        "  if results_df['Technique'][ind]=='CNN_transfer' and results_df['Set'][ind]=='Test':\n",
        "      # print(results_df['F1 Score'][ind])\n",
        "      CNN_trans_prec_values.append(results_df['Precision'][ind])\n",
        "      CNN_trans_f1_values.append(results_df['F1 Score'][ind])\n",
        "\n",
        "\n",
        "# Plot  F1-scores and precision for DNN models and CNN models\n",
        "# Compare the models of each architecture considering these two metrics\n",
        "\n",
        "\n",
        "plt.title(\"DNN_transfer precision in Test Set\")\n",
        "plt.bar(DNN_trans_x_axis, DNN_trans_prec_values)\n",
        "plt.show()\n",
        "\n",
        "plt.title(\"DNN_transfer F1 Score in Test Set\")\n",
        "plt.bar(DNN_trans_x_axis, DNN_trans_f1_values)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.title(\"CNN_transfer precision in Test Set\")\n",
        "plt.bar(CNN_trans_x_axis, DNN_trans_prec_values)\n",
        "plt.show()\n",
        "\n",
        "plt.title(\"CNN_transfer F1 Score in Test Set\")\n",
        "plt.bar(CNN_trans_x_axis, DNN_trans_f1_values)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cor7sRQAOdvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the best DNN_transfer\n",
        "dnn_trans_f1_df = pd.DataFrame(dnn_trans_models, columns=['Model Name', 'Model Object', 'F1-Score'])\n",
        "\n",
        "best_ind = dnn_trans_f1_df['F1-Score'].idxmax()\n",
        "best_dnn = dnn_trans_f1_df.loc[best_ind, 'Model Object']\n",
        "\n",
        "\n",
        "# Find the best CNN_transfer\n",
        "cnn_trans_f1_df = pd.DataFrame(cnn_trans_models, columns=['Model Name', 'Model Object', 'F1-Score'])\n",
        "\n",
        "best_ind = cnn_trans_f1_df['F1-Score'].idxmax()\n",
        "best_dnn = cnn_trans_f1_df.loc[best_ind, 'Model Object']\n"
      ],
      "metadata": {
        "id": "wNnKb8pWIQ9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DNN_x_axis = ['DNN-1', 'DNN-2', 'DNN-3', 'DNN-4', 'DNN-5', 'DNN-6']\n",
        "DNN_prec_values = []\n",
        "DNN_trans_f1_values=[]\n",
        "\n",
        "for ind in results_df.index:\n",
        "  if results_df['Technique'][ind]=='DNN_transfer' and results_df['Set'][ind]=='Test':\n",
        "      DNN_trans_prec_values.append(results_df['Precision'][ind])\n",
        "      DNN_trans_f1_values.append(results_df['F1 Score'][ind])\n",
        "\n",
        "\n",
        "CNN_trans_x_axis = ['CNN-1', 'CNN-2', 'CNN-3', 'CNN-4', 'CNN-5', 'CNN-6']\n",
        "CNN_trans_prec_values = []\n",
        "CNN_trans_f1_values=[]\n",
        "\n",
        "for ind in results_df.index:\n",
        "  if results_df['Technique'][ind]=='CNN_transfer' and results_df['Set'][ind]=='Test':\n",
        "      # print(results_df['F1 Score'][ind])\n",
        "      CNN_trans_prec_values.append(results_df['Precision'][ind])\n",
        "      CNN_trans_f1_values.append(results_df['F1 Score'][ind])\n",
        "\n",
        "\n",
        "# Plot  F1-scores and precision for DNN models and CNN models\n",
        "# Compare the models of each architecture considering these two metrics\n",
        "\n",
        "\n",
        "plt.title(\"DNN_transfer precision in Test Set\")\n",
        "plt.bar(DNN_trans_x_axis, DNN_trans_prec_values)\n",
        "plt.show()\n",
        "\n",
        "plt.title(\"DNN_transfer F1 Score in Test Set\")\n",
        "plt.bar(DNN_trans_x_axis, DNN_trans_f1_values)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.title(\"CNN_transfer precision in Test Set\")\n",
        "plt.bar(CNN_trans_x_axis, DNN_trans_prec_values)\n",
        "plt.show()\n",
        "\n",
        "plt.title(\"CNN_transfer F1 Score in Test Set\")\n",
        "plt.bar(CNN_trans_x_axis, DNN_trans_f1_values)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XdXRkBuNtTxJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}